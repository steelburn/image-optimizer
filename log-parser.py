#!/usr/bin/env python3

"""
log_parser.py - Generate HTML report from image optimization logs
This script parses the log file generated by the image_optimizer.sh script
and creates a detailed HTML report with savings statistics.
"""

import re
import os
import sys
import argparse
from datetime import datetime
from collections import defaultdict

def parse_args():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(description='Generate HTML report from image optimization logs')
    parser.add_argument('-l', '--log-file', default='/var/log/image_optimizer.log',
                        help='Path to the log file (default: /var/log/image_optimizer.log)')
    parser.add_argument('-o', '--output', default='optimization_report.html',
                        help='Output HTML file (default: optimization_report.html)')
    parser.add_argument('-t', '--title', default='Image Optimization Report',
                        help='Report title (default: Image Optimization Report)')
    return parser.parse_args()

def parse_log_file(log_file):
    """Parse the log file and extract optimization data"""
    if not os.path.exists(log_file):
        print(f"Error: Log file '{log_file}' not found.")
        sys.exit(1)
    
    data = {
        'start_time': None,
        'end_time': None,
        'files': [],
        'optimized_count': 0,
        'skipped_count': 0,
        'failed_count': 0,
        'total_size_before': 0,
        'total_size_after': 0,
        'file_types': defaultdict(lambda: {'count': 0, 'saved_bytes': 0, 'original_bytes': 0}),
        'skipped_files': [],
        'failed_files': []
    }
    
    # Regular expressions for parsing the log
    timestamp_pattern = re.compile(r'\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]')
    start_pattern = re.compile(r'Starting image optimization process')
    end_pattern = re.compile(r'Image optimization process completed')
    optimize_pattern = re.compile(r'Optimized (JPEG|PNG|TIFF|PDF|GIF): (.+) \(saved (\d+)%\)')
    skipped_pattern = re.compile(r'Skipped (JPEG|PNG|TIFF|PDF|GIF): (.+)')
    failed_pattern = re.compile(r'Failed to optimize (JPEG|PNG|TIFF|PDF|GIF): (.+)')
    
    with open(log_file, 'r') as f:
        for line in f:
            timestamp_match = timestamp_pattern.search(line)
            if timestamp_match:
                timestamp = timestamp_match.group(1)
                
                # Check for start and end times
                if start_pattern.search(line) and not data['start_time']:
                    data['start_time'] = timestamp
                elif end_pattern.search(line):
                    data['end_time'] = timestamp
                
                # Check for optimized files
                optimize_match = optimize_pattern.search(line)
                if optimize_match:
                    file_type, file_path, saved_percentage = optimize_match.groups()
                    saved_percentage = int(saved_percentage)
                    
                    # Extract file size information
                    file_size_before = 0
                    file_size_after = 0
                    
                    if os.path.exists(file_path):
                        file_size_after = os.path.getsize(file_path)
                        if saved_percentage > 0:
                            file_size_before = int(file_size_after / (1 - saved_percentage / 100))
                        else:
                            file_size_before = file_size_after
                    
                    # Record the file information
                    file_info = {
                        'type': file_type,
                        'path': file_path,
                        'filename': os.path.basename(file_path),
                        'directory': os.path.dirname(file_path),
                        'saved_percentage': saved_percentage,
                        'size_before': file_size_before,
                        'size_after': file_size_after,
                        'saved_bytes': file_size_before - file_size_after,
                        'status': 'optimized'
                    }
                    
                    data['files'].append(file_info)
                    data['optimized_count'] += 1
                    data['total_size_before'] += file_size_before
                    data['total_size_after'] += file_size_after
                    
                    # Update type statistics
                    data['file_types'][file_type]['count'] += 1
                    data['file_types'][file_type]['saved_bytes'] += (file_size_before - file_size_after)
                    data['file_types'][file_type]['original_bytes'] += file_size_before
                
                # Check for skipped files
                elif skipped_pattern.search(line):
                    skipped_match = skipped_pattern.search(line)
                    if skipped_match:
                        file_type, file_path = skipped_match.groups()
                        data['skipped_count'] += 1
                        data['skipped_files'].append({'path': file_path, 'type': file_type, 'reason': 'Skipped'})
                
                # Check for failed files
                elif failed_pattern.search(line):
                    file_type, file_path = failed_pattern.groups()
                    data['failed_count'] += 1
                    data['failed_files'].append({'path': file_path, 'type': file_type, 'reason': 'Failed'})
    
    return data

def human_readable_size(size_bytes):
    """Convert bytes to human-readable format"""
    if size_bytes == 0:
        return "0 B"
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024
        i += 1
    return f"{size_bytes:.2f} {size_names[i]}"

def generate_html_report(data, title):
    """Generate HTML report based on the parsed data"""
    # Calculate total savings
    total_saved_bytes = data['total_size_before'] - data['total_size_after']
    overall_percentage = (total_saved_bytes / data['total_size_before'] * 100) if data['total_size_before'] > 0 else 0

    # Sort files by savings (most saved first)
    sorted_files = sorted(data['files'], key=lambda x: x['saved_bytes'], reverse=True)

    # Calculate processing time
    start_time = datetime.strptime(data['start_time'], '%Y-%m-%d %H:%M:%S') if data['start_time'] else None
    end_time = datetime.strptime(data['end_time'], '%Y-%m-%d %H:%M:%S') if data['end_time'] else None
    processing_time = (end_time - start_time).total_seconds() if start_time and end_time else 'Unknown'

    # Generate HTML
    html = f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        body {{ font-family: Arial, sans-serif; }}
        table {{ width: 100%; border-collapse: collapse; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; }}
        th {{ background-color: #f4f4f4; }}
        .summary {{ margin-bottom: 20px; }}
    </style>
</head>
<body>
    <h1>{title}</h1>
    <div class="summary">
        <p><strong>Start Time:</strong> {data['start_time'] or 'Unknown'}</p>
        <p><strong>End Time:</strong> {data['end_time'] or 'Unknown'}</p>
        <p><strong>Processing Time:</strong> {processing_time} seconds</p>
        <p><strong>Total Files Processed:</strong> {len(data['files'])}</p>
        <p><strong>Total Files Optimized:</strong> {data['optimized_count']}</p>
        <p><strong>Total Files Skipped:</strong> {data['skipped_count']}</p>
        <p><strong>Total Files Failed:</strong> {data['failed_count']}</p>
        <p><strong>Total Space Saved:</strong> {human_readable_size(total_saved_bytes)} ({overall_percentage:.2f}%)</p>
    </div>
    <h2>File Type Summary</h2>
    <table>
        <tr>
            <th>File Type</th>
            <th>Count</th>
            <th>Total Original Size</th>
            <th>Total Space Saved</th>
        </tr>
"""
    for file_type, stats in data['file_types'].items():
        html += f"""
        <tr>
            <td>{file_type}</td>
            <td>{stats['count']}</td>
            <td>{human_readable_size(stats['original_bytes'])}</td>
            <td>{human_readable_size(stats['saved_bytes'])}</td>
        </tr>
"""
    html += """
    </table>
    <h2>Optimized Files</h2>
    <table>
        <tr>
            <th>File</th>
            <th>Type</th>
            <th>Original Size</th>
            <th>New Size</th>
            <th>Space Saved</th>
            <th>Savings %</th>
        </tr>
"""
    for file in sorted_files:
        html += f"""
        <tr>
            <td>{file['filename']}</td>
            <td>{file['type']}</td>
            <td>{human_readable_size(file['size_before'])}</td>
            <td>{human_readable_size(file['size_after'])}</td>
            <td>{human_readable_size(file['saved_bytes'])}</td>
            <td>{file['saved_percentage']}%</td>
        </tr>
"""
    html += """
    </table>
    <h2>Skipped Files</h2>
    <table>
        <tr>
            <th>File</th>
            <th>Reason</th>
        </tr>
"""
    for file in data.get('skipped_files', []):
        html += f"""
        <tr>
            <td>{file['path']}</td>
            <td>{file.get('reason', 'Unknown')}</td>
        </tr>
"""
    html += """
    </table>
    <h2>Failed Files</h2>
    <table>
        <tr>
            <th>File</th>
            <th>Reason</th>
        </tr>
"""
    for file in data.get('failed_files', []):
        html += f"""
        <tr>
            <td>{file['path']}</td>
            <td>{file.get('reason', 'Unknown')}</td>
        </tr>
"""
    html += """
    </table>
</body>
</html>
"""
    return html

def main():
    """Main function"""
    args = parse_args()
    data = parse_log_file(args.log_file)
    html = generate_html_report(data, args.title)
    with open(args.output, 'w') as f:
        f.write(html)
    print(f"Report saved to {args.output}")

if __name__ == "__main__":
    main()
